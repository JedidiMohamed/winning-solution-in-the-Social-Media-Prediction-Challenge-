{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from LIB.utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_json(\"./train.zip\")\n",
    "test=pd.read_json(\"./test_questions.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_columns=[]\n",
    "for col in train.columns : \n",
    "    try :\n",
    "         train[col].unique()\n",
    "    except : \n",
    "        json_columns.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities\n",
      "user\n",
      "entities\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "col_to_remove=[\"contributors\",\"retweeted\",\"coordinates\",\"extended_entities\",\"geo\",\"place\",\"quoted_status\",\"retweeted_status\"]\n",
    "train.drop(col_to_remove,axis=1,inplace=True)\n",
    "test.drop(col_to_remove,axis=1,inplace=True)\n",
    "\n",
    "json_columns=[]\n",
    "for col in train.columns : \n",
    "    try :\n",
    "         train[col].unique()\n",
    "    except : \n",
    "        json_columns.append(col)  \n",
    "def parse_json(x):\n",
    "    for col in json_columns :\n",
    "        print(col)\n",
    "        for key  in x[col].iloc[0].keys():\n",
    "            x[col+\"_\"+key]=x[col].apply(lambda x: x[key])\n",
    "    return x \n",
    "train=parse_json(train)\n",
    "test=parse_json(test)\n",
    "json_columns=[]\n",
    "for col in train.columns : \n",
    "    try :\n",
    "         a=train[col].unique()\n",
    "    except : \n",
    "        json_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"entities_symbols\",\"entities_hashtags\",\"entities_urls\"]\n",
    "for col in cols  : \n",
    "    train[col]=train[col].apply(lambda x : x if len(x)>0 else  np.nan)\n",
    "    test[col]=test[col].apply(lambda x : x if len(x)>0 else  np.nan)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_remove=[\"entities\",\"id_str\",\"in_reply_to_screen_name\",\"in_reply_to_status_id_str\",\"in_reply_to_user_id_str\",\n",
    "              \"quoted_status_id_str\",\"text\",\"user\",\"entities_symbols\",\"user_time_zone\",\"user_time_zone\",\n",
    "              \"user_profile_sidebar_fill_color\",\"user_profile_banner_url\",\"user_is_translator\",\n",
    "              \"user_has_extended_profile\",\"user_translator_type\",\"user_profile_link_color\",\"user_screen_name\",                                                        \n",
    "               \"user_profile_link_color\",\"user_profile_background_image_url\",\n",
    "               \"user_utc_offset\",\"user_protected\",\"user_profile_background_color\",\n",
    "              \"user_geo_enabled\",\"user_profile_image_url\",\"user_profile_use_background_image\",\"user_description\",\n",
    "               \"user_profile_image_url_https\",\"user_profile_background_tile\",\"user_following\",\"user_contributors_enabled\",\n",
    "               \"user_id_str\",\"user_name\",\"user_profile_background_image_url_https\",\"user_profile_sidebar_border_color\",\n",
    "               \"user_default_profile_image\",\"user_url\",\"user_notifications\",\"user_profile_text_color\" ,\"user_lang\",\n",
    "              \"quoted_status_id\",\"user_follow_request_sent\",\"favorited\"]\n",
    "\n",
    "train[\"len_text\"]=train.text.apply(lambda x :len(x.split(\" \")))\n",
    "test[\"len_text\"]=train.text.apply(lambda x :len(x.split(\" \")))\n",
    "\n",
    "train.drop(col_to_remove,axis=1,inplace=True)\n",
    "test.drop(col_to_remove,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_columns=[]\n",
    "for col in train.columns : \n",
    "    try :\n",
    "         a=train[col].unique()\n",
    "    except : \n",
    "        json_columns.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(x):\n",
    "    x[\"created_at\"]=pd.to_datetime(x[\"created_at\"])\n",
    "    x[\"year\"]=x[\"created_at\"].dt.year\n",
    "    x[\"month\"]=x[\"created_at\"].dt.month       \n",
    "    x[\"dayofweek\"]=x[\"created_at\"].dt.dayofweek\n",
    "    x[\"hour\"]=x[\"created_at\"].dt.hour\n",
    "    return x \n",
    "train=time_features(train)\n",
    "test=time_features(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "user_location\n",
      "user_id\n",
      "user_default_profile\n",
      "user_verified\n",
      "truncated\n",
      "source\n",
      "lang\n",
      "is_quote_status\n",
      "user_is_translation_enabled\n"
     ]
    }
   ],
   "source": [
    "col_to_factorize=[\"year\",\"user_location\",\"user_id\",\"user_default_profile\",\"user_verified\",\n",
    "                 \"truncated\", \"source\" ,\"lang\",\"is_quote_status\",\"user_is_translation_enabled\"]\n",
    "map_categorical_feautres(Data=[train,test],columns=col_to_factorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"is_reply_to_status_id\"]=train[\"in_reply_to_status_id\"].apply(lambda x: 1  if  np.isnan(x)  else  0 ) \n",
    "test[\"is_reply_to_status_id\"]=test[\"in_reply_to_status_id\"].apply(lambda x: 1  if  np.isnan(x)  else  0 ) \n",
    "train[\"is_reply_to_user_id\"]=train[\"in_reply_to_user_id\"].apply(lambda x: 1 if np.isnan(x)  else  0 ) \n",
    "test[\"is_reply_to_user_id\"]=test[\"in_reply_to_user_id\"].apply(lambda x: 1 if np.isnan(x)  else  0 ) \n",
    "train[\"reply_to_user_id_count\"]=train.groupby(\"in_reply_to_user_id\").in_reply_to_user_id.transform(\"count\").fillna(0)\n",
    "test[\"reply_to_user_id_count\"]=test.groupby(\"in_reply_to_user_id\").in_reply_to_user_id.transform(\"count\").fillna(0)\n",
    "\n",
    "train[\"reply_to_status_id_count\"]=train.groupby(\"in_reply_to_status_id\").in_reply_to_user_id.transform(\"count\").fillna(0)\n",
    "test[\"reply_to_status_id_count\"]=test.groupby(\"in_reply_to_status_id\").in_reply_to_user_id.transform(\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"count_entities_user_mentions\"]=train[\"entities_user_mentions\"].apply(len)\n",
    "test[\"count_entities_user_mentions\"]=test[\"entities_user_mentions\"].apply(len)\n",
    "\n",
    "train[\"count_entities_hashtags\"]=train[\"entities_hashtags\"].fillna(\"\").apply(len)\n",
    "test[\"count_entities_hashtags\"]=test[\"entities_hashtags\"].fillna(\"\").apply(len)\n",
    "\n",
    "train[\"count_entities_urls\"]=train[\"entities_urls\"].fillna(\"\").apply(len)\n",
    "test[\"count_entities_urls\"]=test[\"entities_urls\"].fillna(\"\").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_idf=pd.read_csv(\"../data_proc/TF_IDF_20.csv\")\n",
    "# TF_idf=pd.read_csv(\"./TF_IDF_50_new.csv\")\n",
    "\n",
    "\n",
    "train=train.merge(TF_idf,on=\"id\",how=\"left\")\n",
    "test=test.merge(TF_idf,on=\"id\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=\"_0\"\n",
    "train.to_csv(\"../data_proc/train{}.csv\".format(v),index=False)\n",
    "test.to_csv(\"../data_proc/test{}.csv\".format(v),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -r ../LIB/AE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
